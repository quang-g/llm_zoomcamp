{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e497593-578f-48aa-b6b5-6476f212cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_prefix = 'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/03-evaluation/'\n",
    "docs_url = url_prefix + 'search_evaluation/documents-with-ids.json'\n",
    "documents = requests.get(docs_url).json()\n",
    "\n",
    "ground_truth_url = url_prefix + 'search_evaluation/ground-truth-data.csv'\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3478f68a-d30b-4779-9273-228fe7118717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc061e20-63b2-4d74-9744-0b3c9cba60da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'When does the course begin?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'document': 'c02e79ef'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b7d51cd-6f65-42ca-a190-1635b90d1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idx = {d['id']: d for d in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91400c0-72c5-4cb6-9c5f-18455c56ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            cnt = cnt + 1\n",
    "\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "def evaluate(ground_truth, search_function):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        doc_id = q['document']\n",
    "        results = search_function(query = q['question'], course = q['course'])\n",
    "        relevance = [d['id'] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9670c65d-dfca-48f8-919e-205603b92384",
   "metadata": {},
   "source": [
    "## Q1. Minsearch Text\n",
    "## Index Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d28ca5de-c6ae-437b-a7d2-e2b224bb5dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x782834ebf0e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"section\", \"text\"],\n",
    "    keyword_fields=[\"course\", \"id\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa5206d-7f87-4bf3-b2c5-eb2f98342418",
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = {'question': 1.5, 'section': 0.1}\n",
    "\n",
    "def minsearch_search(query, course):\n",
    "    results = index.search(\n",
    "        query=query, \n",
    "        boost_dict=boost,\n",
    "        filter_dict={'course': course},\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a095a7f-9470-4c73-8dff-d8a75c61e8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4627/4627 [00:13<00:00, 337.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.848714069591528, 'mrr': 0.7288235717887772}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, minsearch_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec25a26-81a7-4234-b80b-7ede8810d5e7",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e46817-2960-426e-ae5d-7bb88fc1b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be97e403-7751-4f01-89d0-c1815475a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c18040e-120b-42ca-a9c1-a0e16220375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Embeddings for the \"question\" field\n",
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9deff9c-bd1c-43dc-a626-94f0b2522baf",
   "metadata": {},
   "source": [
    "## Q2. Vector search for question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45234c6-a404-4b67-96d7-0579ed457e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x782834547fe0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1097583d-28d8-4ff6-a0f3-e911749a5312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4627/4627 [00:06<00:00, 742.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR@5': 0.3568510914199265}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def minsearch_search_fn(query, course, k=5):\n",
    "    \"\"\"\n",
    "    Embed the query with the SAME fitted pipeline and search in Minsearch with a course filter.\n",
    "    \"\"\"\n",
    "    # TF-IDF expects an iterable -> wrap in a list\n",
    "    q_mat = pipeline.transform([query])       # shape: (1, n_components)\n",
    "    # Make a 1D vector\n",
    "    q_vec = q_mat.toarray()[0] if hasattr(q_mat, \"toarray\") else q_mat[0]\n",
    "\n",
    "    return vindex.search(q_vec, filter_dict={'course': course}, num_results=k)\n",
    "\n",
    "def mrr_at_k(ground_truth, k=5):\n",
    "    \"\"\"\n",
    "    Compute Mean Reciprocal Rank@k.\n",
    "    Assumes each ground_truth item has keys: 'question', 'course', 'document' (relevant doc id).\n",
    "    \"\"\"\n",
    "    total_rr = 0.0\n",
    "    n = 0\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        results = minsearch_search_fn(q['question'], q['course'], k=k)\n",
    "        # Find rank (1-based) of the relevant document\n",
    "        rank = None\n",
    "        for i, d in enumerate(results):\n",
    "            if d.get('id') == q['document']:\n",
    "                rank = i + 1\n",
    "                break\n",
    "        if rank is not None:\n",
    "            total_rr += 1.0 / rank  # reciprocal rank (0 if not found)\n",
    "        n += 1\n",
    "\n",
    "    return total_rr / n if n else 0.0\n",
    "\n",
    "# --- Run it ---\n",
    "mrr5 = mrr_at_k(ground_truth, k=5)\n",
    "print({\"MRR@5\": mrr5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc254d6-1073-4991-abe7-817a13b7fc86",
   "metadata": {},
   "source": [
    "## Q3. Vector search for questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df5d1fd9-ba6e-4c91-b12d-18f67def4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in documents:\n",
    "    t = doc['question'] + ' ' + doc['text']\n",
    "    texts.append(t)\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=3),\n",
    "    TruncatedSVD(n_components=128, random_state=1)\n",
    ")\n",
    "X = pipeline.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab23847-7c56-473b-bdf9-a94a22ea7a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x782832c96480>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vindex = VectorSearch(keyword_fields={'course'})\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f99e3a1c-2a21-45d5-ac54-4642b9917d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4627/4627 [00:06<00:00, 693.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRR@5': 0.6711944384410349, 'HitRate@5': 0.8210503566025502}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def minsearch_search_fn(query, course, k=5):\n",
    "    \"\"\"\n",
    "    Embed the query with the SAME fitted pipeline and search in Minsearch with a course filter.\n",
    "    \"\"\"\n",
    "    q_mat = pipeline.transform([query])       # shape: (1, n_components)\n",
    "    q_vec = q_mat.toarray()[0] if hasattr(q_mat, \"toarray\") else q_mat[0]\n",
    "\n",
    "    return vindex.search(q_vec, filter_dict={'course': course}, num_results=k)\n",
    "\n",
    "def evaluate_at_k(ground_truth, k=5):\n",
    "    \"\"\"\n",
    "    Compute MRR@k and Hit Rate@k.\n",
    "    \"\"\"\n",
    "    total_rr = 0.0\n",
    "    hits = 0\n",
    "    n = 0\n",
    "\n",
    "    for q in tqdm(ground_truth):\n",
    "        results = minsearch_search_fn(q['question'], q['course'], k=k)\n",
    "\n",
    "        rank = None\n",
    "        for i, d in enumerate(results):\n",
    "            if d.get('id') == q['document']:\n",
    "                rank = i + 1\n",
    "                break\n",
    "\n",
    "        if rank is not None:\n",
    "            total_rr += 1.0 / rank      # reciprocal rank\n",
    "            hits += 1                   # count a hit if relevant doc is in top-k\n",
    "        n += 1\n",
    "\n",
    "    return {\n",
    "        f'MRR@{k}': total_rr / n if n else 0.0,\n",
    "        f'HitRate@{k}': hits / n if n else 0.0\n",
    "    }\n",
    "\n",
    "# --- Run it ---\n",
    "metrics_k5 = evaluate_at_k(ground_truth, k=5)\n",
    "print(metrics_k5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d662186e-2a53-4e31-a807-88a8a2225fe6",
   "metadata": {},
   "source": [
    "## Q5. Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb910d-696d-48c0-85ec-845561d3f122",
   "metadata": {},
   "source": [
    "Now let's evaluate the following settings in Qdrant:\n",
    "\n",
    "- text = doc['question'] + ' ' + doc['text']\n",
    "- model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "- limit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f4ec3d-b5f9-4ead-9498-5da51414902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2611f8e1-d90b-4193-bd5b-f1a9bbd41769",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea8ab60-b801-48c8-885d-eb735f289b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0117b54-1dab-4a6f-8ff9-c4c163f55c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = doc['question'] + ' ' + doc['text']\n",
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "EMBEDDING_DIMENSIONALITY=512\n",
    "limit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99335d58-bb14-4397-961a-decf43fd4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"llmzoomcamp-evaluation-homework\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0afee0f-2929-4908-b2ea-3a8519961786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "608005b3-2bce-4250-b3ff-5d090dd35ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the collection name\n",
    "collection_name = \"llmzoomcamp-evaluation-homework\"\n",
    "\n",
    "# Create the collection with specified vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed79d7f-ad19-4d9d-a896-226456007989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact matching on string metadata fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d06356c-3d2e-4d03-ab05-be05837d35f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6bd6475-51e4-485e-9a0a-2caea01e948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "id = 0\n",
    "\n",
    "for doc in documents:\n",
    "    point = models.PointStruct(\n",
    "        id=id,\n",
    "        # Embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "        vector=models.Document(\n",
    "            text=doc['text'],\n",
    "            model=model_handle\n",
    "        ),\n",
    "        # Save all needed metadata fields\n",
    "        payload={\n",
    "            \"text\": doc['text'],\n",
    "            \"section\": doc['section'],\n",
    "            \"course\": doc['course'],\n",
    "            \"id\": doc['id']\n",
    "        }\n",
    "    )\n",
    "    points.append(point)\n",
    "    id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf5dcac5-e5a2-41ef-937f-8f0efed9a39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserting to Qdrant: 100%|██████████████████████████████████████████████████████████████| 8/8 [02:47<00:00, 20.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# client.upsert(\n",
    "#     collection_name=collection_name,\n",
    "#     points=points\n",
    "# )\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "BATCH_SIZE = 128  # adjust depending on your memory / API limits\n",
    "\n",
    "for i in tqdm(range(0, len(points), BATCH_SIZE), desc=\"Upserting to Qdrant\"):\n",
    "    batch = points[i : i + BATCH_SIZE]\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=batch\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b13c11f0-6e90-4939-b59d-e0bc5cab2552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Homework - Are late submissions of homework allowed?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'be5bfee4'},\n",
       " {'text': 'when trying to:\\nURL=\"spark://$HOSTNAME:7077\"\\nspark-submit \\\\\\n--master=\"{$URL}\" \\\\\\n06_spark_sql.py \\\\\\n--input_green=data/pq/green/2021/*/ \\\\\\n--input_yellow=data/pq/yellow/2021/*/ \\\\\\n--output=data/report-2021\\nand you get errors like the following (SUMMARIZED):\\nWARN Utils: Your hostname, <HOSTNAME> resolves to a loopback address..\\nWARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address Setting default log level to \"WARN\".\\nException in thread \"main\" org.apache.spark.SparkException: Master must either be yarn or start with spark, mesos, k8s, or local at …\\nTry replacing --master=\"{$URL}\"\\nwith --master=$URL (edited)\\nExtra edit for spark version 3.4.2 - if encountering:\\n`Error: Unrecognized option: --master=`\\n→ Replace `--master=\"{$URL}\"` with  `--master \"${URL}\"`',\n",
       "  'section': 'Module 5: pyspark',\n",
       "  'question': '`spark-submit` errors',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '504b8570'},\n",
       " {'text': 'You will have two attempts for a project. If the first project deadline is over and you’re late or you submit the project and fail the first attempt, you have another chance to submit the project with the second attempt.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Project - What is Project Attemp #1 and Project Attempt #2 exactly?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '48b533a8'},\n",
       " {'text': \"All mage files are in your /home/src/folder where you saved your credentials.json so you should be able to access them locally. You will see a folder for ‘Pipelines’,  'data loaders', 'data transformers' & 'data exporters' - inside these will be the .py or .sql files for the blocks you created in your pipeline.\\nRight click & ‘download’ the pipeline itself to your local machine (which gives you metadata, pycache and other files)\\nAs above, download each .py/.sql file that corresponds to each block you created for the pipeline. You'll find these under 'data loaders', 'data transformers' 'data exporters'\\nMove the downloaded files to your GitHub repo folder & commit your changes.\",\n",
       "  'section': 'Module 2: Workflow Orchestration',\n",
       "  'question': 'Git - What Files Should I Submit for Homework 2 & How do I get them out of MAGE:',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '0513ab8a'},\n",
       " {'text': 'Try deleting data you’ve saved to your VM locally during ETLs\\nKill processes related to deleted files\\nDownload ncdu and look for large files (pay particular attention to files related to Prefect)\\nIf you delete any files related to Prefect, eliminate caching from your flow code',\n",
       "  'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\",\n",
       "  'question': 'VMs - What do I do if my VM runs out of space?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'bba0da04'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minsearch_search(\"What if I submit homeworks late?\", \"data-engineering-zoomcamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f46b1ab-9f93-4954-962c-eb83ddfa5782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an id -> question lookup once (if you have the documents list)\n",
    "doc_question_by_id = {d[\"id\"]: d.get(\"question\") for d in documents}  # safe even if some don't have 'question'\n",
    "\n",
    "def format_qdrant_results(resp, question_lookup=None):\n",
    "    \"\"\"\n",
    "    Convert Qdrant QueryResponse -> list of dicts with desired fields.\n",
    "    If question_lookup is provided (dict id->question), add 'question'.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for sp in resp.points:\n",
    "        payload = sp.payload or {}\n",
    "        item = {\n",
    "            \"text\": payload.get(\"text\"),\n",
    "            \"section\": payload.get(\"section\"),\n",
    "            \"course\": payload.get(\"course\"),\n",
    "            \"id\": payload.get(\"id\") or sp.id,  # prefer payload id; fallback to numeric point id\n",
    "        }\n",
    "        if question_lookup is not None:\n",
    "            item[\"question\"] = question_lookup.get(item[\"id\"])\n",
    "        out.append(item)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc9b43b9-ffd5-47be-aba6-951215607218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_course(query, course=\"data-engineering-zoomcamp\"):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        query_filter=models.Filter( # filter by course name\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return format_qdrant_results(results, question_lookup=doc_question_by_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12e48958-9ed3-4025-8648-f04e18e5160e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       "  'section': 'General course-related questions',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'be5bfee4',\n",
       "  'question': 'Homework - Are late submissions of homework allowed?'},\n",
       " {'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '7842b56a',\n",
       "  'question': 'Course - Can I still join the course after the start date?'},\n",
       " {'text': 'You will have two attempts for a project. If the first project deadline is over and you’re late or you submit the project and fail the first attempt, you have another chance to submit the project with the second attempt.',\n",
       "  'section': 'General course-related questions',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '48b533a8',\n",
       "  'question': 'Project - What is Project Attemp #1 and Project Attempt #2 exactly?'},\n",
       " {'text': 'This can help avoid schema issues in the homework. \\nDownload files locally and use the ‘upload files’ button in GCS at the desired path. You can upload many files at once. You can also choose to upload a folder.',\n",
       "  'section': \"error: Error while reading table: trips_data_all.external_fhv_tripdata, error message: Parquet column 'DOlocationID' has type INT64 which does not match the target cpp_type DOUBLE.\",\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': 'b9b3ef9f',\n",
       "  'question': 'Homework - Uploading files to GCS via GUI'},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'id': '0bbf41ec',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_in_course(\"What if I submit homeworks late?\", \"data-engineering-zoomcamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5a4a366-0258-4d32-8428-4d87434500d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4627/4627 [01:08<00:00, 67.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8417981413442835, 'mrr': 0.7331028023917593}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth,search_in_course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039bc1a6-ae2c-41ea-a85b-040591550df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
